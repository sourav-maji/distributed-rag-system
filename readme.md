# FastAPI RAG with Redis Queue (RQ)

A **distributed Retrieval-Augmented Generation (RAG)** system built using **FastAPI**, **LangChain**, **Qdrant**, and **Redis Queue (RQ)**.

This project demonstrates how to handle RAG queries asynchronously using a background worker, making it scalable and production-ready.

---

## ğŸš€ Features

- PDF document ingestion and vector indexing
- Semantic search using Qdrant
- Asynchronous query processing with Redis Queue (RQ)
- FastAPI-based REST API
- Background workers for retrieval & generation
- Clean, modular architecture

---

## ğŸ§± Tech Stack

- **Python 3.9+**
- **FastAPI**
- **LangChain**
- **Qdrant (Vector Database)**
- **Redis + RQ**
- **OpenAI Embeddings**
- **Docker**

---

## ğŸ“‚ Project Structure

```bash
distributed-rag-system/
â”œâ”€â”€ client/
â”‚   â””â”€â”€ rq_client.py        # Redis + RQ configuration
â”œâ”€â”€ queues/
â”‚   â””â”€â”€ worker.py           # RAG worker (retrieval + generation)
â”œâ”€â”€ server.py               # FastAPI app
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ index.py                # PDF ingestion & vector indexing
â”œâ”€â”€ retrieve.py             # Local retrieval testing
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                    # API keys (ignored)
â”œâ”€â”€ README.md
â””â”€â”€ data/
    â””â”€â”€ sample.pdf
```
## ğŸ“Š Architecture Diagram
```mermaid
flowchart LR
    User -->|HTTP Request| FastAPI
    FastAPI -->|Enqueue Job| Redis[(Redis Queue)]
    Redis --> Worker[RQ Worker]

    Worker -->|Vector Search| Qdrant[(Qdrant Vector DB)]
    Worker -->|Context| LLM[OpenAI / LLM]

    Qdrant -->|Relevant Chunks| Worker
    LLM -->|Generated Answer| Worker

    Worker -->|Result| Redis
    FastAPI -->|Fetch Result| Redis
    FastAPI -->|HTTP Response| User
```

## âš™ï¸ Setup Instructions
### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/sourav-maji/distributed-rag-system.git

cd distributed-rag-system

```

### 2ï¸âƒ£ Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install --upgrade pip
pip install -r requirements.txt
```
### 4ï¸âƒ£ Start Redis
```bash
docker run -p 6379:6379 redis
```
### 5ï¸âƒ£ Start Qdrant
```bash
docker run -p 6333:6333 qdrant/qdrant
```
### Qdrant dashboard:

```bash
http://localhost:6333/dashboard
````
### 6ï¸âƒ£ Configure Environment Variables
Create a .env file:
```env
OPENAI_API_KEY=your_openai_api_key
```
### ğŸ“¥ Index Documents
Add PDFs to the data/ folder, then run:
```bash
python index.py
```

This will:
- Load PDF documents
- Split them into chunks
- Generate embeddings
- Store vectors in Qdrant

### ğŸ” Start RQ Worker
Open a new terminal:
```
rq worker rag-queue
```
### ğŸš€ Start FastAPI Server

```
uvicorn rag_queue.server:app --reload
```
Server will be available at:
```
http://127.0.0.1:8000
```

## ğŸ§  How It Works
1. Documents are embedded and stored in Qdrant
2. User sends a query to FastAPI
3. Query is queued using Redis Queue (RQ)
4. Worker retrieves relevant chunks
5. LLM generates a context-aware response
6. Result is returned asynchronously

## ğŸ“Œ Why RQ?
- Non-blocking API
- Simple distributed processing
- Easy horizontal scaling
- Better than synchronous RAG for production

## â­ Acknowledgements
- LangChain
- Qdrant
- Redis & RQ
- OpenAI